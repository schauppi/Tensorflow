{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hyperparameter_Grid_Search.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHokXEyRvAPP"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2lbNVRK-bPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503bcd90-e95c-4bf6-b6c5-7963fc23dad6"
      },
      "source": [
        "#load mnist data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ4K1d1c-dXk"
      },
      "source": [
        "#normalize the data\n",
        "x_train = (x_train.astype(\"float32\")) / 255.0\n",
        "x_test = (x_test.astype(\"float32\")) / 255.0\n",
        "\n",
        "#reshape the data to have a single channel\n",
        "x_train = x_train.reshape((x_train.shape[0], 28,28,1))\n",
        "x_test = x_test.reshape((x_test.shape[0], 28,28,1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0yflkoK-fCI"
      },
      "source": [
        "#build the model\n",
        "def create_model():\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5d68mVa-gKu"
      },
      "source": [
        "#create the model\n",
        "model = KerasClassifier(build_fn=create_model)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hio11XQf-iS9"
      },
      "source": [
        "#grid search parameters\n",
        "batch_size = [10, 20, 40]\n",
        "epochs = [10, 20, 30]\n",
        "\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqEvmPmf-j28"
      },
      "source": [
        "#n_jobs = process will use all cores on the machine\n",
        "#cv = use 3 fold grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=2)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vuivaKF-lPl",
        "outputId": "6119312a-d5d0-4d31-f39b-9952b3c93343",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "grid_result = grid.fit(x_train, y_train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 31.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 9s 2ms/step - loss: 0.2933 - accuracy: 0.9091\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0495 - accuracy: 0.9853\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0331 - accuracy: 0.9898\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0223 - accuracy: 0.9926\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0157 - accuracy: 0.9952\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0133 - accuracy: 0.9953\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0092 - accuracy: 0.9971\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0076 - accuracy: 0.9975\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0075 - accuracy: 0.9974\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0061 - accuracy: 0.9979\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0036 - accuracy: 0.9991\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0051 - accuracy: 0.9988\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0043 - accuracy: 0.9988\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0051 - accuracy: 0.9987\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0031 - accuracy: 0.9989\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0030 - accuracy: 0.9989\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0027 - accuracy: 0.9990\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0036 - accuracy: 0.9988\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0017 - accuracy: 0.9994\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0027 - accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0029 - accuracy: 0.9990\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0022 - accuracy: 0.9991\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0034 - accuracy: 0.9991\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72NXXW_t-mwm",
        "outputId": "4fa4b6a2-7466-4c66-ae62-e74867a667e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(grid_result.best_score_, grid_result.best_params_)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9887333313624064 {'batch_size': 20, 'epochs': 30}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJR_7EJhk9r0"
      },
      "source": [
        "#build the model\n",
        "def create_model_optimizer(optimizer=\"Adam\"):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Gt3FslkGjT",
        "outputId": "65c99483-1d55-4aec-c599-3d377fc06cbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Model for optimizer optimization\n",
        "model_optimizer = KerasClassifier(build_fn=create_model_optimizer, epochs=30, batch_size=20)\n",
        "optimizer = [\"SGD\", \"RMSprop\", \"Adagrad\", \"Adadelta\", \"Adam\", \"Adamax\", \"Nadam\"]\n",
        "param_grid_optimizer = dict(optimizer=optimizer)\n",
        "grid_optimizer = GridSearchCV(estimator=model_optimizer, param_grid=param_grid_optimizer, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_optimizer_result = grid_optimizer.fit(x_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  21 out of  21 | elapsed: 34.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.2959 - accuracy: 0.9101\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0483 - accuracy: 0.9852\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0334 - accuracy: 0.9894\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0241 - accuracy: 0.9921\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0184 - accuracy: 0.9932\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0131 - accuracy: 0.9958\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0129 - accuracy: 0.9960\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0096 - accuracy: 0.9967\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0062 - accuracy: 0.9982\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0054 - accuracy: 0.9980\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0049 - accuracy: 0.9982\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0048 - accuracy: 0.9984\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0021 - accuracy: 0.9993\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0055 - accuracy: 0.9984\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0031 - accuracy: 0.9988\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0037 - accuracy: 0.9988\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0042 - accuracy: 0.9987\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0024 - accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0025 - accuracy: 0.9992\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0029 - accuracy: 0.9991\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0028 - accuracy: 0.9992\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0016 - accuracy: 0.9996\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0020 - accuracy: 0.9994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uviQZqL1mREL",
        "outputId": "cb3cc264-90e7-4d66-82e4-a44b3d270837",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(grid_optimizer_result.best_score_, grid_optimizer_result.best_params_)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9891833464304606 {'optimizer': 'Adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHAEVdXLuYdq"
      },
      "source": [
        "#build the model\n",
        "def create_model_lr(learning_rate=0.01):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Conv2D(32, (3,3), activation=\"relu\"))\n",
        "    model.add(keras.layers.MaxPool2D(2,2))\n",
        "    model.add(keras.layers.Flatten())\n",
        "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnD0-Sn_uZjF",
        "outputId": "41dbc8e3-65e2-4028-fd54-d5cb3bd6ada1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Model for learning rate optimization\n",
        "model_lr = KerasClassifier(build_fn=create_model_lr, epochs=30, batch_size=20)\n",
        "learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid_lr = dict(learning_rate=learning_rate)\n",
        "grid_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid_lr, cv=3, n_jobs=-1, verbose=2)\n",
        "grid_lr_result = grid_lr.fit(x_train, y_train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 22.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.3020 - accuracy: 0.9110\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0472 - accuracy: 0.9859\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0330 - accuracy: 0.9899\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0224 - accuracy: 0.9929\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0161 - accuracy: 0.9947\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0126 - accuracy: 0.9960\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0104 - accuracy: 0.9968\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0085 - accuracy: 0.9968\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0065 - accuracy: 0.9979\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0060 - accuracy: 0.9978\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0053 - accuracy: 0.9980\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0042 - accuracy: 0.9985\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0048 - accuracy: 0.9985\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0040 - accuracy: 0.9986\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0040 - accuracy: 0.9985\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0034 - accuracy: 0.9989\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0037 - accuracy: 0.9986\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0037 - accuracy: 0.9988\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0028 - accuracy: 0.9991\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0026 - accuracy: 0.9991\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0030 - accuracy: 0.9992\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0036 - accuracy: 0.9988\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0022 - accuracy: 0.9993\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0051 - accuracy: 0.9984\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0021 - accuracy: 0.9992\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0019 - accuracy: 0.9995\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0025 - accuracy: 0.9993\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0034 - accuracy: 0.9990\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0028 - accuracy: 0.9993\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0018 - accuracy: 0.9995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKpUUFNz49Jl",
        "outputId": "7f9ea39b-be35-48b5-e6e4-79b472ff2920",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(grid_lr_result.best_score_, grid_lr_result.best_params_)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9888000090916952 {'learning_rate': 0.001}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYMzHor_W8a"
      },
      "source": [
        "#build final model\n",
        "final_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
        "    keras.layers.MaxPool2D(2,2),\n",
        "    keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
        "    keras.layers.MaxPool2D(2,2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")                             \n",
        "])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX3AyqlX_05W",
        "outputId": "e68b8a32-5570-427b-c049-a50d0ffe4d4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 11, 11, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 108,618\n",
            "Trainable params: 108,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWzWWPMyADVd"
      },
      "source": [
        "#compile finale model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "final_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoreaJADAqZy",
        "outputId": "bf71c796-16a4-4e5e-b48e-fe31c4141d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#train the model\n",
        "batch_size = 20\n",
        "epochs = 30\n",
        "history = final_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3000/3000 [==============================] - 8s 2ms/step - loss: 0.2999 - accuracy: 0.9084 - val_loss: 0.0610 - val_accuracy: 0.9799\n",
            "Epoch 2/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0472 - accuracy: 0.9854 - val_loss: 0.0318 - val_accuracy: 0.9898\n",
            "Epoch 3/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.0333 - val_accuracy: 0.9888\n",
            "Epoch 4/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0198 - accuracy: 0.9932 - val_loss: 0.0345 - val_accuracy: 0.9888\n",
            "Epoch 5/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0352 - val_accuracy: 0.9893\n",
            "Epoch 6/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.0319 - val_accuracy: 0.9905\n",
            "Epoch 7/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.0312 - val_accuracy: 0.9910\n",
            "Epoch 8/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0336 - val_accuracy: 0.9909\n",
            "Epoch 9/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0056 - accuracy: 0.9983 - val_loss: 0.0368 - val_accuracy: 0.9904\n",
            "Epoch 10/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0459 - val_accuracy: 0.9888\n",
            "Epoch 11/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 0.0571 - val_accuracy: 0.9890\n",
            "Epoch 12/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0454 - val_accuracy: 0.9892\n",
            "Epoch 13/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0038 - accuracy: 0.9985 - val_loss: 0.0406 - val_accuracy: 0.9917\n",
            "Epoch 14/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 0.0531 - val_accuracy: 0.9892\n",
            "Epoch 15/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0041 - accuracy: 0.9986 - val_loss: 0.0488 - val_accuracy: 0.9909\n",
            "Epoch 16/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0535 - val_accuracy: 0.9900\n",
            "Epoch 17/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0565 - val_accuracy: 0.9912\n",
            "Epoch 18/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0508 - val_accuracy: 0.9914\n",
            "Epoch 19/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0774 - val_accuracy: 0.9858\n",
            "Epoch 20/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0625 - val_accuracy: 0.9892\n",
            "Epoch 21/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0590 - val_accuracy: 0.9900\n",
            "Epoch 22/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0553 - val_accuracy: 0.9913\n",
            "Epoch 23/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0718 - val_accuracy: 0.9879\n",
            "Epoch 24/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0636 - val_accuracy: 0.9902\n",
            "Epoch 25/30\n",
            "3000/3000 [==============================] - 8s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0802 - val_accuracy: 0.9884\n",
            "Epoch 26/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 0.0673 - val_accuracy: 0.9889\n",
            "Epoch 27/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0670 - val_accuracy: 0.9912\n",
            "Epoch 28/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0649 - val_accuracy: 0.9898\n",
            "Epoch 29/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0743 - val_accuracy: 0.9906\n",
            "Epoch 30/30\n",
            "3000/3000 [==============================] - 7s 2ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0673 - val_accuracy: 0.9905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yYo8m2tA6nI"
      },
      "source": [
        "accuracy = history.history[\"accuracy\"]\n",
        "loss = history.history[\"loss\"]\n",
        "val_accuracy = history.history[\"val_accuracy\"]\n",
        "val_loss = history.history[\"val_loss\"]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEDJvyLKB6mu",
        "outputId": "dae32ecc-773e-4fec-95d4-c2b151a56bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "plt.plot(accuracy, label=\"accuracy\")\n",
        "plt.plot(loss, label=\"loss\")\n",
        "plt.plot(val_accuracy, label=\"val_accuracy\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3774aff0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}